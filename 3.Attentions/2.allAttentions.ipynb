{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d393517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ffmou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e233bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4879b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1-input x1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2-input x2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b33595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input query-word \"jouney\"\n",
    "x_2=inputs[1]\n",
    "#for all matrices(key,query,value)-dimension should match with input matrix(3x2 here)\n",
    "\n",
    "d_in=inputs.shape[1]#3\n",
    "d_out=2\n",
    "\n",
    "#in gt models,input and output dimensions are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8fc6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "#matrix initialization with random values for query weight,key weight and value weight matrices with dimension of 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53079d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "#calculating query vector,key vector,value vector for input(\"journey\")\n",
    "\n",
    "query_2=x_2@W_query\n",
    "key_2=x_2@W_key\n",
    "value_2=x_2@W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b982c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys shape:  torch.Size([6, 2])\n",
      "Values shape:  torch.Size([6, 2])\n",
      "queries shape:  torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "#now obtain a matrix that contains keys,queries,values for all the inputs\n",
    "\n",
    "keys=inputs@W_key\n",
    "queries=inputs@W_query\n",
    "values=inputs@W_value\n",
    "\n",
    "print(\"Keys shape: \",keys.shape)\n",
    "print(\"Values shape: \",values.shape)\n",
    "print(\"queries shape: \",queries.shape)\n",
    "\n",
    "#here all the tokens are projected down from 3d space(token embeddings) to 2d space(query,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7615b370",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot() missing 1 required positional arguments: \"tensor\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#finding attention score  for second query(\"jouney\")\u001b[39;00m\n\u001b[32m      2\u001b[39m keys_2=keys[\u001b[32m1\u001b[39m] \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m attn_score_2=\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(attn_score_2)\n",
      "\u001b[31mTypeError\u001b[39m: dot() missing 1 required positional arguments: \"tensor\""
     ]
    }
   ],
   "source": [
    "#finding attention score  for second query(\"jouney\")\n",
    "keys_2=keys[1] \n",
    "attn_score_2=torch.dot(keys_2)\n",
    "print(attn_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94065195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#finding attention score  for second query(\"journey\")  with respect to all other keys\n",
    "attn_scores_2=query_2@keys.T#query_2 represent the value from queries matrix for word \"journey\" (2nd row)\n",
    "print(attn_scores_2)\n",
    "print(attn_scores_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84832d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "#finding attention score  for all queries  with respect to all other keys\n",
    "attn_scores=queries@keys.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k=keys.shape[-1]#dimension of keys matrix(here 2d)\n",
    "#attention weight for 2nd token(\"journey\")\n",
    "attn_weights_2=torch.softmax(attn_scores_2/d_k**0.5,dim=-1)#d_k**0.5=sqrt(2) and dim=-1 means summing up all the columnvalues in row for softmax denominator in each value\n",
    "print(attn_weights_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax with scaling:  tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "Softmax after scaling(tensor * 8):  tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "#reasons for applying sqrt(dimension) - stability in learning\n",
    "tensor=torch.tensor([0.1,-0.2,0.3,-0.2,0.5])\n",
    "\n",
    "softmax_result=torch.softmax(tensor,dim=-1)\n",
    "print(\"Softmax with scaling: \",softmax_result)\n",
    "\n",
    "tensor_scaled=tensor*8\n",
    "softmax_result_scaled=torch.softmax(tensor_scaled,dim=-1)\n",
    "print(\"Softmax after scaling(tensor * 8): \",softmax_result_scaled)\n",
    "\n",
    "#here in result,before scaling the values in results are distributed correctly\n",
    "#but after scaling the tensor,the probability gets scattered and highest value in tensor captures 80%(0.5 in input tensor captures 80% in scaled_tensor).\n",
    "#it causes instability in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "#calculating context vector for word journey with values\n",
    "context_vec_2=attn_weights_2@values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94516793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing a self attention python class\n",
    "import torch.nn as nn\n",
    "#nn is a fundamental building block of pytorch ,which provides necssary services for model creation and management\n",
    "class SelfAttentionV1(nn.Module):\n",
    "\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_keys=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_values=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_queries=nn.Parameter(torch.rand(d_in,d_out))\n",
    "\n",
    "    \n",
    "    def forward(self,x):#x represenst input embedding vectors\n",
    "\n",
    "        keys=x@self.W_keys\n",
    "        queries=x@self.W_queries\n",
    "        values=x@self.W_values\n",
    "\n",
    "        attn_scores=queries@keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8413, 0.8945],\n",
      "        [0.8719, 0.9321],\n",
      "        [0.8713, 0.9312],\n",
      "        [0.8240, 0.8726],\n",
      "        [0.8292, 0.8783],\n",
      "        [0.8361, 0.8867]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v1=SelfAttentionV1(d_in,d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299faf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing a self attention python class\n",
    "import torch.nn as nn\n",
    "#nn is a fundamental building block of pytorch ,which provides necssary services for model creation and management\n",
    "#Linear is used because it effectively performs matrix multiplicationa when bias units are disabled and it has an optimized weight initialization scheme while initializing matrices with random values contributing to more stable and effective model training\n",
    "class SelfAttentionV2(nn.Module):\n",
    "\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_keys=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_values=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_queries=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "\n",
    "    \n",
    "    def forward(self,x):#x represenst input embedding vectors\n",
    "\n",
    "        keys=self.W_keys(x)\n",
    "        queries=self.W_queries(x)\n",
    "        values=self.W_values(x)\n",
    "\n",
    "        attn_scores=queries@keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7148, -0.0405],\n",
      "        [ 0.7132, -0.0415],\n",
      "        [ 0.7132, -0.0413],\n",
      "        [ 0.7136, -0.0388],\n",
      "        [ 0.7140, -0.0348],\n",
      "        [ 0.7133, -0.0415]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v2=SelfAttentionV2(d_in,d_out)\n",
    "print(sa_v2(inputs))\n",
    "#output from self attention version 1 is different from version 2 because the weight initialization is more sophisticated for linear than parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e6085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1757, 0.1646, 0.1655, 0.1603, 0.1812, 0.1527],\n",
      "        [0.1767, 0.1622, 0.1634, 0.1602, 0.1884, 0.1492],\n",
      "        [0.1763, 0.1623, 0.1635, 0.1605, 0.1876, 0.1498],\n",
      "        [0.1727, 0.1639, 0.1646, 0.1629, 0.1799, 0.1559],\n",
      "        [0.1667, 0.1660, 0.1661, 0.1669, 0.1682, 0.1661],\n",
      "        [0.1767, 0.1623, 0.1635, 0.1601, 0.1881, 0.1492]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#casual attention -masking out future tokens\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1-input x1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2-input x2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "queries=sa_v2.W_queries(inputs)\n",
    "keys=sa_v2.W_keys(inputs)\n",
    "attn_scores=queries@keys.T\n",
    "attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b606c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#use pytorch tril(triangle lower) function to create a mask where the values above diagonal is zero\n",
    "context_length=attn_scores.shape[0]\n",
    "mask_simple=torch.tril(torch.ones(context_length,context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1757, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1767, 0.1622, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1763, 0.1623, 0.1635, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1727, 0.1639, 0.1646, 0.1629, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1660, 0.1661, 0.1669, 0.1682, 0.0000],\n",
      "        [0.1767, 0.1623, 0.1635, 0.1601, 0.1881, 0.1492]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#masking the above diagonal in attention weights\n",
    "masked_attn_scores=attn_weights*mask_simple\n",
    "print(masked_attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5214, 0.4786, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3512, 0.3233, 0.3256, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2600, 0.2468, 0.2479, 0.2453, 0.0000, 0.0000],\n",
      "        [0.1998, 0.1991, 0.1992, 0.2002, 0.2017, 0.0000],\n",
      "        [0.1767, 0.1623, 0.1635, 0.1601, 0.1881, 0.1492]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#again normalizing the attention weights to sum up to 1 in each row in masked attention scores\n",
    "row_sums=masked_attn_scores.sum(dim=1,keepdims=True)\n",
    "#calculating sum of all values in each row\n",
    "masked_simple_norm=masked_attn_scores/row_sums\n",
    "#dividing each value in a row with that row sum\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bc5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0957,  0.0035,  0.0107, -0.0339,  0.1391, -0.1026],\n",
      "        [ 0.0618, -0.0595, -0.0491, -0.0770,  0.1525, -0.1779],\n",
      "        [ 0.0587, -0.0583, -0.0483, -0.0747,  0.1466, -0.1722],\n",
      "        [ 0.0326, -0.0414, -0.0350, -0.0496,  0.0906, -0.1120],\n",
      "        [-0.0146, -0.0200, -0.0193, -0.0122, -0.0014, -0.0196],\n",
      "        [ 0.0655, -0.0549, -0.0446, -0.0743,  0.1533, -0.1737]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#more efficient way to mask is to mask the attention scores\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0957,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.0618, -0.0595,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.0587, -0.0583, -0.0483,    -inf,    -inf,    -inf],\n",
      "        [ 0.0326, -0.0414, -0.0350, -0.0496,    -inf,    -inf],\n",
      "        [-0.0146, -0.0200, -0.0193, -0.0122, -0.0014,    -inf],\n",
      "        [ 0.0655, -0.0549, -0.0446, -0.0743,  0.1533, -0.1737]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#masking upper diagonal of attention scores with -infinity\n",
    "mask=torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
    "masked=attn_scores.masked_fill(mask.bool(),-torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56227930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5214, 0.4786, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3512, 0.3233, 0.3256, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2600, 0.2468, 0.2479, 0.2453, 0.0000, 0.0000],\n",
      "        [0.1998, 0.1991, 0.1992, 0.2002, 0.2017, 0.0000],\n",
      "        [0.1767, 0.1623, 0.1635, 0.1601, 0.1881, 0.1492]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#normaliizng using softmax\n",
    "attn_weights=torch.softmax(masked/keys.shape[-1]**0.5,dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c7e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 2., 2., 0., 2., 2.],\n",
      "        [2., 2., 2., 0., 0., 2.],\n",
      "        [2., 0., 2., 0., 0., 0.],\n",
      "        [0., 2., 2., 2., 2., 0.],\n",
      "        [2., 2., 2., 0., 0., 2.],\n",
      "        [2., 2., 0., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#dropout layer to mask out 50% which means masking out half of attention weights\n",
    "dropout=torch.nn.Dropout(0.5)\n",
    "example=torch.ones(6,6)\n",
    "print(example)\n",
    "#50% of weights in each row is switched off \n",
    "#50% means half of elements in matrix are reduced to 0. to compensate this,other values are sacled up to 2(1/0.5=2)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a68220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7023, 0.6465, 0.6512, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4935, 0.4958, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3982, 0.0000, 0.4004, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3246, 0.3270, 0.3202, 0.3761, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "#creating a batch of inputs\n",
    "batch=torch.stack((inputs,inputs),dim=0)\n",
    "print(batch.shape)\n",
    "#th result is a 3d tensor consisting of 2 input texts with 6 tokens each where each token is a 3-dimensional embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#casual attention class-handling batches of inputs\n",
    "class CasualAttention(nn.Module):\n",
    "\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.W_keys=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_values=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_queries=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "        #buffer are automatically moved to appropriate device(GPU or CPU) along with model which will help in training LLM\n",
    "    \n",
    "    def forward(self,x):#x represenst input embedding vectors\n",
    "        b,num_tokens,d_in=x.shape#b-batches,num_tokens-no.of.tokens in each input,d_in-dimensions for each token\n",
    "        keys=self.W_keys(x)\n",
    "        queries=self.W_queries(x)\n",
    "        values=self.W_values(x)\n",
    "\n",
    "        attn_scores=queries@keys.transpose(1,2)#here in input dimension is (2,6,3) we need only want that (6,3) so use indexing to achive that(1,2).6-1st ind,3-2nd ind\n",
    "        #filling upper diagonal with mask of negative infinity\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)#here :num_tokens is used to account for cases where number of tokens in the batch is smaller than supported context_size\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        #adding dropout layer\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        context_vecs=attn_weights@values\n",
    "        return context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473aab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context vector shape:  torch.Size([2, 6, 2])\n",
      "tensor([[[-0.5740,  0.2727],\n",
      "         [-0.7249,  0.1854],\n",
      "         [-0.7714,  0.1586],\n",
      "         [-0.6997,  0.1210],\n",
      "         [-0.6560,  0.1309],\n",
      "         [-0.6445,  0.1027]],\n",
      "\n",
      "        [[-0.5740,  0.2727],\n",
      "         [-0.7249,  0.1854],\n",
      "         [-0.7714,  0.1586],\n",
      "         [-0.6997,  0.1210],\n",
      "         [-0.6560,  0.1309],\n",
      "         [-0.6445,  0.1027]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length=batch.shape[1]#batch shape-(2,6,3) here 6 is the context length\n",
    "ca=CasualAttention(d_in,d_out,context_length,0.0)\n",
    "context_vectors=ca(batch)\n",
    "print(\"context vector shape: \",context_vectors.shape)\n",
    "print(context_vectors)\n",
    "#here result is a 3d vector with 2 batches of inputs with each having 6 tokens with each token having a 2d context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi head attention- multiple simple attention for single input \n",
    "#each input embedding vector will have multiple instances of key,value,query weights matrices and multiple queries,keys,values matrices and multiple context vectors and those context vectors are conactenation at last\n",
    "\n",
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        #creating multiple instances of casual attention\n",
    "        self.heads=nn.ModuleList(\n",
    "            [CasualAttention(d_in,d_out,context_length,dropout,qkv_bias)\n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads],dim=-1)\n",
    "        #concatenating context vectors from each head along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5740,  0.2727, -0.3132, -0.2272],\n",
      "         [-0.7249,  0.1854, -0.2330,  0.0261],\n",
      "         [-0.7714,  0.1586, -0.2079,  0.1126],\n",
      "         [-0.6997,  0.1210, -0.1678,  0.1287],\n",
      "         [-0.6560,  0.1309, -0.1702,  0.1722],\n",
      "         [-0.6445,  0.1027, -0.1425,  0.1594]],\n",
      "\n",
      "        [[-0.5740,  0.2727, -0.3132, -0.2272],\n",
      "         [-0.7249,  0.1854, -0.2330,  0.0261],\n",
      "         [-0.7714,  0.1586, -0.2079,  0.1126],\n",
      "         [-0.6997,  0.1210, -0.1678,  0.1287],\n",
      "         [-0.6560,  0.1309, -0.1702,  0.1722],\n",
      "         [-0.6445,  0.1027, -0.1425,  0.1594]]], grad_fn=<CatBackward0>)\n",
      "shape:  torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length=batch.shape[1]\n",
    "d_in,d_out=3,2\n",
    "mha=MultiHeadAttentionWrapper(d_in,d_out,context_length,0.0,num_heads=2)\n",
    "mha_context_vecs=mha(batch)\n",
    "print(mha_context_vecs)\n",
    "print(\"shape: \",mha_context_vecs.shape)\n",
    "#the result is a 3d vector with batch of size 2 with each input having 6 tokens and each token having a context vector of 4d context vector(4d beacuse 2d context vector from 2 heads added )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3481284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improving multi head attention forward method by processing multiple heads sequentially\n",
    "#here instaed of making multiple weight matrices for key,value and query we take one large matrix (for eg: if there are 2 heads with 2 separate weight matrix ,the output will be 2 different matrixes with dimension of (3x2) then add it along columns will result in (3x4) matrix \n",
    "# but here we are taking one large weight matrix with dimension of (3x4) and find query,key,value matrices and split them with num_heads(2) ,result in two 3x2 matrices)\n",
    "import torch.nn as nn\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0),\"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out=d_out\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim = d_out//num_heads #finding dimension of each head\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.out_proj=nn.Linear(d_out,d_out)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "\n",
    "        #shape for keys,queries,values matrix=(b,num_tokens,d_out)\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "\n",
    "        #split the larger matrices(keys,queries,values) according to num of heads\n",
    "        #unroll last dimension to split the matrices according to no of heads:(b,num_tokens,d_out)->(b,num_tokens,num_heads,head_dim)\n",
    "        keys=keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        queries=queries.view(b,num_tokens,self.num_heads,self.head_dim) \n",
    "        values=values.view(b,num_tokens,self.num_heads,self.head_dim) \n",
    "\n",
    "        #grouping according to num of heads by transposing\n",
    "        #(b,num_tokens,num_heads,head_dim)->(b,num_heads,num_tokens,head_dim)\n",
    "        keys=keys.transpose(1,2)\n",
    "        queries=queries.transpose(1,2)\n",
    "        values=values.transpose(1,2)\n",
    "\n",
    "        #computing attention scores\n",
    "        attn_scores=queries@keys.transpose(2,3)\n",
    "        #here, each row i in each head represents the attention score of ith token with respect to all tokens in that head\n",
    "\n",
    "        #implementing mask for upper diagonal\n",
    "        mask_bool=self.mask.bool()[:num_tokens,:num_tokens]\n",
    "\n",
    "        #masking the attention scores\n",
    "        attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)#keys.shape[1] refers to head_dim\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "\n",
    "        #context vector: shape->(b,num_tokens,num_heads,head_dim)\n",
    "        context_vec=(attn_weights@values).transpose(1,2)\n",
    "\n",
    "        #combine heads,where d_out=num_heads*head_dim\n",
    "        context_vec=context_vec.contiguous().view(b,num_tokens,self.d_out)#values are stored sometimes non-contiguously in memory.if dimesnion changed on non-contiguously,it will lead to error.This method(contiguous) makes a new tensor with the same values but stored in a clean, contiguous memory block.\n",
    "        context_vec=self.out_proj(context_vec)#optional projection layer\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1ef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 6])\n",
      "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1125, -0.0561,  0.0454, -0.0234, -0.3247, -0.3030],\n",
      "         [ 0.1194, -0.0501,  0.0347, -0.0637, -0.2797, -0.2612]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1125, -0.0561,  0.0454, -0.0234, -0.3247, -0.3030],\n",
      "         [ 0.1194, -0.0501,  0.0347, -0.0637, -0.2797, -0.2612]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "context vector shape:  torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the tensor with 3 rows and 6 columns\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
    "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
    "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
    ")\n",
    "\n",
    "batch=torch.stack((inputs,inputs),dim=0)\n",
    "print(batch.shape)\n",
    "\n",
    "batch_size,context_length,d_in=batch.shape\n",
    "d_out=6\n",
    "mha=MultiHeadAttention(d_in,d_out,context_length,2,0.0)\n",
    "context_vecs=mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context vector shape: \",context_vecs.shape)\n",
    "#result is a 3d vector for 2 inputs in batch with each input having 3 tokens and each token with 6d context vectors(6d because of multiple heads,if divide it by num_heads(6/2=3),it will split into two 3d vectors each vector is for separate heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab7f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
