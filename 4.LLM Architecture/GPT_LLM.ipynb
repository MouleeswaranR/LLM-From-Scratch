{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7438fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config for gpt-2 small model\n",
    "\n",
    "GPT_CONFIG_124M={\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":768,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"qkv_bias\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778bca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy gpt model class\n",
    "\n",
    "#step 1:use a placeholder for transformer block\n",
    "\n",
    "#step 2:use a placeholder for LayerNorm\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "class DummyGPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self,cfg):#cgf-configuration of gpt-2 model\n",
    "        super().__init__()\n",
    "        self.tok_emb=nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb=nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb=nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        #use a placeholder for transformer block\n",
    "        self.trf_blocks=nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        #use a placeholder for LayerNorm\n",
    "        self.final_norm=DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head=nn.Linear(\n",
    "            cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,in_idx):\n",
    "        batch_size,seq_len=in_idx.shape#batch_size-no of inputs,seq_len=length of no of tokens of each input in batch\n",
    "        tok_embeds=self.tok_emb(in_idx)#token embeddings for input token ids each token id will have 768 dimensional token embedding\n",
    "        pos_embeds=self.pos_emb(torch.arange(seq_len,device=in_idx.device))#here arange is used for each input sequence there will be n number of tokens ,it is creating positional embedding vectors for n number of tokens.positional embedding created for one input sequence is used for all the other input sequences\n",
    "        x=tok_embeds+pos_embeds\n",
    "        #input token embeddings\n",
    "        x=self.drop_emb(x)\n",
    "        #dropout layer\n",
    "        x=self.trf_blocks(x)\n",
    "        #transformer block-implementing layernorm,multi-head attention,dropout layers\n",
    "        x=self.final_norm(x)\n",
    "        #final norm layer: shape until this step-(num_of_tokens_in_input_seq x number-of-embedding-dimension)\n",
    "        logits=self.out_head(x)\n",
    "        return logits#logitsdimension-(no_of_tokens_input_seq x vocab_size ) each row represents probability for each of the 50527 words to occur in that place\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60c72f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Tokenization\n",
    "\n",
    "import tiktoken\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "batch=[]\n",
    "txt1=\"Every effort moves you\"#for each input , 4 inputs and 4 prediction tasks happens here because of 4 tokens in this input sequence\n",
    "txt2=\"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch=torch.stack(batch,dim=0)\n",
    "print(batch)\n",
    "#a single batch contains token ids for two separate input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab97640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([2, 4, 50256])\n",
      "tensor([[[ 0.4128, -0.8998, -0.5579,  ...,  0.4135,  0.3933, -1.0613],\n",
      "         [ 0.5321,  0.4538, -0.3093,  ...,  1.1302, -0.4263, -1.3800],\n",
      "         [-0.4274, -0.0532,  1.5788,  ...,  0.6545,  0.4722,  1.7405],\n",
      "         [-1.1740,  0.2963,  1.8822,  ...,  0.0439,  0.0202,  0.0705]],\n",
      "\n",
      "        [[-0.4007, -1.3970, -0.2163,  ...,  0.4030,  0.6206, -0.7461],\n",
      "         [ 0.8890, -0.4229, -0.0288,  ...,  1.2841, -0.7089, -0.7428],\n",
      "         [ 0.8619, -0.0722,  1.6096,  ...,  0.6957,  0.2457, -0.4580],\n",
      "         [-0.5883,  0.0320, -0.5026,  ..., -0.3743,  0.4036,  1.0022]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: create a dummy instance of dummy gpt model\n",
    "torch.manual_seed(123)\n",
    "model=DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits=model(batch)\n",
    "print(\"Output shape: \",logits.shape)\n",
    "#the result is a 3d vector for 2 inputs sequences with 4 rows(tokens) each and each row(token)  having the probabilities for all the 50256 tokens\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49124b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Layer Normalization-Simple example\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_example=torch.randn(2,5)#a btch of 2 inputs sequences with each input sequence having 5 inputs\n",
    "layer=nn.Sequential(nn.Linear(5,6),nn.ReLU())#6 outputs for each input sequence with 5 inputs each\n",
    "out=layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d762b4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#finding mean and variance\n",
    "mean=out.mean(dim=-1,keepdim=True)#dim=-1 because finding mean with all values of columns in a row\n",
    "var=out.var(dim=-1,keepdim=True)\n",
    "print(\"Mean: \",mean)\n",
    "print(\"Variance: \",var) \n",
    "#each row is a mean or variance for that input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e6416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:  tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#applying normalization\n",
    "out_norm=(out-mean)/torch.sqrt(var)\n",
    "mean=out_norm.mean(dim=-1,keepdims=True)\n",
    "var=out_norm.var(dim=-1,keepdims=True)\n",
    "print(\"Normalized layer outputs:\\n\",out_norm)\n",
    "print(\"Mean: \",mean)\n",
    "print(\"Variance: \",var)\n",
    "#after normalization,mean for each input sequence is almost zero and variance is one also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd6d812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#here we are getting perfect values ,even though the values are close to zero, turn off scientific mode\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean: \",mean)\n",
    "print(\"Variance: \",var)\n",
    "#now mean=0 and variance=1 for all input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07bdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Normalization Class\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps=1e-5\n",
    "        #eps-to prevent division by zero while normalization in denominator\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        #scale \n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #here x is input: rows-context size ,cols-no of embeddings dimensions for each token\n",
    "        mean=x.mean(dim=-1,keepdims=True)\n",
    "        var=x.var(dim=-1,keepdims=True,unbiased=False)\n",
    "        #here if unbiased=true, we want to apply bessel variance,divide by n-1 instead of n while calculating variance.this is same implementation for gpt models\n",
    "        norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale*norm_x+self.shift\n",
    "    \n",
    "# Step 1: Normalization = ironing clothes\n",
    "\n",
    "# You flatten everything, remove wrinkles, make all shirts look neat.\n",
    "\n",
    "# But now all shirts look too similar.\n",
    "\n",
    "# Step 2: scale = resizing the shirt\n",
    "\n",
    "# Make it tighter or looser.\n",
    "\n",
    "# Step 3: shift = moving the shirt up/down\n",
    "\n",
    "# Adjust the position so it fits perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e310a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln=LayerNorm(emb_dim=5)\n",
    "out_ln=ln(batch_example)\n",
    "mean=out_ln.mean(dim=-1,keepdims=True)\n",
    "var=out_ln.var(dim=-1,keepdims=True,unbiased=False)\n",
    "print(\"Mean:\\n\",mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fba3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GELU Activation class\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5 * x *(1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
    "            (x+0.044715*torch.pow(x,3))\n",
    "        )\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d1a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForward Neural Network used inside Transformer blocks\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        emb = cfg[\"emb_dim\"]\n",
    "        hidden = 4 * emb   # Expanded dimension\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # -------- EXPANSION --------\n",
    "            # Increase embedding size from emb → 4*emb\n",
    "            # Gives the model more capacity and richer feature space\n",
    "            nn.Linear(emb, hidden),\n",
    "\n",
    "            # -------- ACTIVATION --------\n",
    "            # GELU adds non-linearity and helps the network learn complex patterns\n",
    "            GELU(),\n",
    "\n",
    "            # -------- CONTRACTION --------\n",
    "            # Bring dimension back from 4*emb → emb\n",
    "            # Keeps output compatible with the transformer's embedding size\n",
    "            nn.Linear(hidden, emb)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0807fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn=FeedForward(GPT_CONFIG_124M)\n",
    "x=torch.randn(2,3,768)#a btch with 2 inputs each input having 3 tokens and each token with embedding dimension of 768\n",
    "out=ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34208a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding shortcut connections for forward pass\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut=use_shortcut\n",
    "        #layers is a deep neural network with 5 layers and each layer have its input and output neuron size and GELU Activation\n",
    "        self.layers=nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]),GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),GELU())\n",
    "\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            #compute the output of cuurent layer\n",
    "            layer_output=layer(x)\n",
    "\n",
    "            #applying shortcut and also check if input dimesion is equal to the layer output dimesnion\n",
    "            if self.use_shortcut and x.shape==layer_output.shape:\n",
    "                x=x+layer_output\n",
    "            else:\n",
    "                x=layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5469cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[3,3,3,3,3,1]#indicate no of neurons in each layer\n",
    "sample_input=torch.tensor([1.,0.,-1.])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut=ExampleDeepNeuralNetwork(\n",
    "    layer_sizes,use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33daa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model,x):\n",
    "    #Forward pass\n",
    "    output=model(x)\n",
    "    target=torch.tensor([[0.]])\n",
    "\n",
    "    #calculate loss based on how close the target and output are\n",
    "    loss=nn.MSELoss()\n",
    "    loss=loss(output,target)\n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # print the mean absolute gradient of weights in each layer(each layer will have a 3x3 gradient matrix)\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37659e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8137aedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut=ExampleDeepNeuralNetwork(\n",
    "    layer_sizes,use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09488260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete Transformer Block\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps=1e-5\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        var=x.var(dim=-1,keepdim=True)\n",
    "        norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale*norm_x +self.shift\n",
    "    \n",
    "#GELU Activation class\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5 * x *(1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
    "            (x+0.044715*torch.pow(x,3))\n",
    "        ) \n",
    "\n",
    "        )\n",
    "\n",
    "# FeedForward Neural Network used inside Transformer blocks\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        emb = cfg[\"emb_dim\"]\n",
    "        hidden = 4 * emb   # Expanded dimension\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # -------- EXPANSION --------\n",
    "            # Increase embedding size from emb → 4*emb\n",
    "            # Gives the model more capacity and richer feature space\n",
    "            nn.Linear(emb, hidden),\n",
    "\n",
    "            # -------- ACTIVATION --------\n",
    "            # GELU adds non-linearity and helps the network learn complex patterns\n",
    "            GELU(),\n",
    "\n",
    "            # -------- CONTRACTION --------\n",
    "            # Bring dimension back from 4*emb → emb\n",
    "            # Keeps output compatible with the transformer's embedding size\n",
    "            nn.Linear(hidden, emb)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366c478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improving multi head attention forward method by processing multiple heads sequentially\n",
    "#here instaed of making multiple weight matrices for key,value and query we take one large matrix (for eg: if there are 2 heads with 2 separate weight matrix ,the output will be 2 different matrixes with dimension of (3x2) then add it along columns will result in (3x4) matrix \n",
    "# but here we are taking one large weight matrix with dimension of (3x4) and find query,key,value matrices and split them with num_heads(2) ,result in two 3x2 matrices)\n",
    "import torch.nn as nn\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0),\"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out=d_out\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim = d_out//num_heads #finding dimension of each head\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.out_proj=nn.Linear(d_out,d_out)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "\n",
    "        #shape for keys,queries,values matrix=(b,num_tokens,d_out)\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "\n",
    "        #split the larger matrices(keys,queries,values) according to num of heads\n",
    "        #unroll last dimension to split the matrices according to no of heads:(b,num_tokens,d_out)->(b,num_tokens,num_heads,head_dim)\n",
    "        keys=keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        queries=queries.view(b,num_tokens,self.num_heads,self.head_dim) \n",
    "        values=values.view(b,num_tokens,self.num_heads,self.head_dim) \n",
    "\n",
    "        #grouping according to num of heads by transposing\n",
    "        #(b,num_tokens,num_heads,head_dim)->(b,num_heads,num_tokens,head_dim)\n",
    "        keys=keys.transpose(1,2)\n",
    "        queries=queries.transpose(1,2)\n",
    "        values=values.transpose(1,2)\n",
    "\n",
    "        #computing attention scores\n",
    "        attn_scores=queries@keys.transpose(2,3)\n",
    "        #here, each row i in each head represents the attention score of ith token with respect to all tokens in that head\n",
    "\n",
    "        #implementing mask for upper diagonal\n",
    "        mask_bool=self.mask.bool()[:num_tokens,:num_tokens]\n",
    "\n",
    "        #masking the attention scores\n",
    "        attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)#keys.shape[1] refers to head_dim\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "\n",
    "        #context vector: shape->(b,num_tokens,num_heads,head_dim)\n",
    "        context_vec=(attn_weights@values).transpose(1,2)\n",
    "\n",
    "        #combine heads,where d_out=num_heads*head_dim\n",
    "        context_vec=context_vec.contiguous().view(b,num_tokens,self.d_out)#values are stored sometimes non-contiguously in memory.if dimesnion changed on non-contiguously,it will lead to error.This method(contiguous) makes a new tensor with the same values but stored in a clean, contiguous memory block.\n",
    "        context_vec=self.out_proj(context_vec)#optional projection layer\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25ac5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer Block\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        #Multihead attention instance for converting embedding vectors into context vectors\n",
    "        self.att=MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        #FeedForward Neural Network instance\n",
    "        self.ff=FeedForward(cfg)\n",
    "        #LayerNormalization instance 1 \n",
    "        self.norm1=LayerNorm(cfg[\"emb_dim\"])\n",
    "        #LayerNormalization instance 2\n",
    "        self.norm2=LayerNorm(cfg[\"emb_dim\"])\n",
    "        #Dropout layer\n",
    "        self.drop_shortcut=nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self,x):\n",
    "        #input x is preserved for adding after output from first part of transformer\n",
    "        shortcut=x\n",
    "        #################Part 1 of transformer################\n",
    "        #First input passing through Layer normalization layer 1\n",
    "        x=self.norm1(x)\n",
    "        #output from LayerNorm layer 1 passing through multi head attention\n",
    "        x=self.att(x) # shape[batch_size,num_tokens,emb_size]\n",
    "        #dropout layer\n",
    "        x=self.drop_shortcut(x)\n",
    "        #output is added with input(initial/original input)\n",
    "        x=x+shortcut\n",
    "\n",
    "        #################Part 2 of transformer################\n",
    "        #input x(output from 1st part of transformer) is preserved for adding after output from 2nd part of transformer\n",
    "        shortcut=x\n",
    "        # input from 1st part of transformer passing through Layer normalization layer 1\n",
    "        x=self.norm2(x)\n",
    "        #ouput from LayerNorm 2nd layer is passed through feed forward neural network\n",
    "        x=self.ff(x)\n",
    "        #output from FeedForward NN is passed through dropout layer\n",
    "        x=self.drop_shortcut(x)\n",
    "        #ouput from above dropout layer is added with shortcut input(output of 1st part of transformer)\n",
    "        x=x+shortcut\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ca418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "torch.manual_seed(123)\n",
    "x=torch.rand(2,4,768)\n",
    "block=TransformerBlock(GPT_CONFIG_124M)\n",
    "output=block(x)\n",
    "print(\"Input shape:\",x.shape)\n",
    "print(\"Output shape:\",output.shape)\n",
    "#same shape for input and output\n",
    "#remember transformer block only doing operstions with layer normaliation,multi head attention ,dropout ,shortcut connections,feedforward neural network while keeping the dimension of input same as through the output\n",
    "#but the output vectors contains a rich information about each token how its related with other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbad58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
