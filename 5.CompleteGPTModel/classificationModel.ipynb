{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "dac92c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dac92c35",
        "outputId": "18052c4a-4ae8-41bf-e071-80ae6d9b2911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "#Classification Finetuning on sms spam\n",
        "\n",
        "#Downloading dataset\n",
        "\n",
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "40bcd89f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "40bcd89f",
        "outputId": "5cf052f2-42a6-4a5e-965a-90e1ebf32dd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(data_file_path,sep=\"\\t\",header=None,names=[\"Label\",\"Text\"])\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "104c39a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104c39a7",
        "outputId": "972b9564-2c18-4356-fd2a-d223d92c6a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#creating a balanced dataset\n",
        "def create_balanced_dataset(df):\n",
        "    #count no of instances of \"spam\"\n",
        "    num_spam=df[df[\"Label\"]==\"spam\"].shape[0]\n",
        "\n",
        "    #taking no of ham instances equal to no of spam instances\n",
        "    ham_subset=df[df[\"Label\"]==\"ham\"].sample(num_spam,random_state=123)\n",
        "\n",
        "    #combining both equal no of ham and spam instances\n",
        "    balanced_df=pd.concat([ham_subset,df[df[\"Label\"]==\"spam\"]])\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df=create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "fae7ffa0",
      "metadata": {
        "id": "fae7ffa0"
      },
      "outputs": [],
      "source": [
        "#assinging ham to 0 and ham to 1(heare we are dealing with only 2 tokens)\n",
        "balanced_df[\"Label\"]=balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "af1075d6",
      "metadata": {
        "id": "af1075d6"
      },
      "outputs": [],
      "source": [
        "#splitting data - 70% for training, 10% for validation and 20% for testing\n",
        "\n",
        "def random_split(df,train_frac,validation_frac):\n",
        "    #shuffle the entire Dataframe\n",
        "    df=df.sample(frac=1,random_state=123).reset_index(drop=True)\n",
        "\n",
        "    #calculating splitting indices\n",
        "    train_end=int(len(df)*train_frac)\n",
        "    validation_end=train_end+int(len(df)*validation_frac)\n",
        "\n",
        "    train_df=df[:train_end]\n",
        "    validation_df=df[train_end:validation_end]\n",
        "    test_df=df[validation_end:]\n",
        "\n",
        "    return train_df,validation_df,test_df\n",
        "\n",
        "train_df,validation_df,test_df=random_split(balanced_df,0.7,0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "3f96c6a1",
      "metadata": {
        "id": "3f96c6a1"
      },
      "outputs": [],
      "source": [
        "#convert the dataframes into csv files\n",
        "train_df.to_csv(\"train.csv\",index=None)\n",
        "validation_df.to_csv(\"validation.csv\",index=None)\n",
        "test_df.to_csv(\"test.csv\",index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "991fb264",
      "metadata": {
        "id": "991fb264"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "23ee032e",
      "metadata": {
        "id": "23ee032e"
      },
      "outputs": [],
      "source": [
        "#example\n",
        "#config for gpt-2 small model\n",
        "\n",
        "GPT_CONFIG_124M={\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_length\":1024,\n",
        "    \"emb_dim\":768,\n",
        "    \"n_heads\":12,\n",
        "    \"n_layers\":12,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"qkv_bias\":False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "7c7eb649",
      "metadata": {
        "id": "7c7eb649"
      },
      "outputs": [],
      "source": [
        "#Complete Transformer Block\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self,emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps=1e-5\n",
        "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self,x):\n",
        "        mean=x.mean(dim=-1,keepdim=True)\n",
        "        var=x.var(dim=-1,keepdim=True)\n",
        "        norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
        "        return self.scale*norm_x +self.shift\n",
        "\n",
        "#GELU Activation class\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return 0.5 * x *(1+torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
        "            (x+0.044715*torch.pow(x,3))\n",
        "        )\n",
        "\n",
        "        )\n",
        "\n",
        "# FeedForward Neural Network used inside Transformer blocks\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        emb = cfg[\"emb_dim\"]\n",
        "        hidden = 4 * emb   # Expanded dimension\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # -------- EXPANSION --------\n",
        "            # Increase embedding size from emb → 4*emb\n",
        "            # Gives the model more capacity and richer feature space\n",
        "            nn.Linear(emb, hidden),\n",
        "\n",
        "            # -------- ACTIVATION --------\n",
        "            # GELU adds non-linearity and helps the network learn complex patterns\n",
        "            GELU(),\n",
        "\n",
        "            # -------- CONTRACTION --------\n",
        "            # Bring dimension back from 4*emb → emb\n",
        "            # Keeps output compatible with the transformer's embedding size\n",
        "            nn.Linear(hidden, emb)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "894424d9",
      "metadata": {
        "id": "894424d9"
      },
      "outputs": [],
      "source": [
        "#improving multi head attention forward method by processing multiple heads sequentially\n",
        "#here instaed of making multiple weight matrices for key,value and query we take one large matrix (for eg: if there are 2 heads with 2 separate weight matrix ,the output will be 2 different matrixes with dimension of (3x2) then add it along columns will result in (3x4) matrix\n",
        "# but here we are taking one large weight matrix with dimension of (3x4) and find query,key,value matrices and split them with num_heads(2) ,result in two 3x2 matrices)\n",
        "import torch.nn as nn\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,d_in,d_out,context_length,num_heads,dropout,qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out%num_heads==0),\"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out=d_out\n",
        "        self.num_heads=num_heads\n",
        "        self.head_dim = d_out//num_heads #finding dimension of each head\n",
        "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "        self.out_proj=nn.Linear(d_out,d_out)\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,num_tokens,d_in=x.shape\n",
        "\n",
        "        #shape for keys,queries,values matrix=(b,num_tokens,d_out)\n",
        "        keys=self.W_key(x)\n",
        "        queries=self.W_query(x)\n",
        "        values=self.W_value(x)\n",
        "\n",
        "        #split the larger matrices(keys,queries,values) according to num of heads\n",
        "        #unroll last dimension to split the matrices according to no of heads:(b,num_tokens,d_out)->(b,num_tokens,num_heads,head_dim)\n",
        "        keys=keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "        queries=queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "        values=values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "        #grouping according to num of heads by transposing\n",
        "        #(b,num_tokens,num_heads,head_dim)->(b,num_heads,num_tokens,head_dim)\n",
        "        keys=keys.transpose(1,2)\n",
        "        queries=queries.transpose(1,2)\n",
        "        values=values.transpose(1,2)\n",
        "\n",
        "        #computing attention scores\n",
        "        attn_scores=queries@keys.transpose(2,3)\n",
        "        #here, each row i in each head represents the attention score of ith token with respect to all tokens in that head\n",
        "\n",
        "        #implementing mask for upper diagonal\n",
        "        mask_bool=self.mask.bool()[:num_tokens,:num_tokens]\n",
        "\n",
        "        #masking the attention scores\n",
        "        attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)#keys.shape[1] refers to head_dim\n",
        "        attn_weights=self.dropout(attn_weights)\n",
        "\n",
        "        #context vector: shape->(b,num_tokens,num_heads,head_dim)\n",
        "        context_vec=(attn_weights@values).transpose(1,2)\n",
        "\n",
        "        #combine heads,where d_out=num_heads*head_dim\n",
        "        context_vec=context_vec.contiguous().view(b,num_tokens,self.d_out)#values are stored sometimes non-contiguously in memory.if dimesnion changed on non-contiguously,it will lead to error.This method(contiguous) makes a new tensor with the same values but stored in a clean, contiguous memory block.\n",
        "        context_vec=self.out_proj(context_vec)#optional projection layer\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "3457c407",
      "metadata": {
        "id": "3457c407"
      },
      "outputs": [],
      "source": [
        "#Transformer Block\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,cfg):\n",
        "        super().__init__()\n",
        "        #Multihead attention instance for converting embedding vectors into context vectors\n",
        "        self.att=MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        #FeedForward Neural Network instance\n",
        "        self.ff=FeedForward(cfg)\n",
        "        #LayerNormalization instance 1\n",
        "        self.norm1=LayerNorm(cfg[\"emb_dim\"])\n",
        "        #LayerNormalization instance 2\n",
        "        self.norm2=LayerNorm(cfg[\"emb_dim\"])\n",
        "        #Dropout layer\n",
        "        self.drop_shortcut=nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self,x):\n",
        "        #input x is preserved for adding after output from first part of transformer\n",
        "        shortcut=x\n",
        "        #################Part 1 of transformer################\n",
        "        #First input passing through Layer normalization layer 1\n",
        "        x=self.norm1(x)\n",
        "        #output from LayerNorm layer 1 passing through multi head attention\n",
        "        x=self.att(x) # shape[batch_size,num_tokens,emb_size]\n",
        "        #dropout layer\n",
        "        x=self.drop_shortcut(x)\n",
        "        #output is added with input(initial/original input)\n",
        "        x=x+shortcut\n",
        "\n",
        "        #################Part 2 of transformer################\n",
        "        #input x(output from 1st part of transformer) is preserved for adding after output from 2nd part of transformer\n",
        "        shortcut=x\n",
        "        # input from 1st part of transformer passing through Layer normalization layer 1\n",
        "        x=self.norm2(x)\n",
        "        #ouput from LayerNorm 2nd layer is passed through feed forward neural network\n",
        "        x=self.ff(x)\n",
        "        #output from FeedForward NN is passed through dropout layer\n",
        "        x=self.drop_shortcut(x)\n",
        "        #ouput from above dropout layer is added with shortcut input(output of 1st part of transformer)\n",
        "        x=x+shortcut\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "21b09f3f",
      "metadata": {
        "id": "21b09f3f"
      },
      "outputs": [],
      "source": [
        "#Complete GPT model class - 124M parameters\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class GPTModel(nn.Module):\n",
        "\n",
        "    def __init__(self,cfg):#cgf-configuration of gpt-2 model\n",
        "        super().__init__()\n",
        "        self.tok_emb=nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "        self.pos_emb=nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
        "        self.drop_emb=nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        #use a placeholder for transformer block\n",
        "        self.trf_blocks=nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        #use a placeholder for LayerNorm\n",
        "        self.final_norm=LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head=nn.Linear(\n",
        "            cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self,in_idx):\n",
        "        batch_size,seq_len=in_idx.shape#batch_size-no of inputs,seq_len=length of no of tokens of each input in batch\n",
        "        tok_embeds=self.tok_emb(in_idx)#token embeddings for input token ids each token id will have 768 dimensional token embedding\n",
        "        pos_embeds=self.pos_emb(torch.arange(seq_len,device=in_idx.device))#here arange is used for each input sequence there will be n number of tokens ,it is creating positional embedding vectors for n number of tokens.positional embedding created for one input sequence is used for all the other input sequences\n",
        "        x=tok_embeds+pos_embeds\n",
        "        #input token embeddings\n",
        "        x=self.drop_emb(x)\n",
        "        #dropout layer\n",
        "        x=self.trf_blocks(x)\n",
        "        #transformer block-implementing layernorm,multi-head attention,dropout layers\n",
        "        x=self.final_norm(x)\n",
        "        #final norm layer: shape until this step-(num_of_tokens_in_input_seq x number-of-embedding-dimension)\n",
        "        logits=self.out_head(x)\n",
        "        return logits#logitsdimension-(no_of_tokens_input_seq x vocab_size ) each row represents probability for each of the 50527 words to occur in that place as next token to current token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "c18f5ac4",
      "metadata": {
        "id": "c18f5ac4"
      },
      "outputs": [],
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "888592f3",
      "metadata": {
        "id": "888592f3"
      },
      "outputs": [],
      "source": [
        "NEW_CONFIG.update({\"context_length\":1024,\"qkv_bias\":True})\n",
        "gpt=GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "86206a1e",
      "metadata": {
        "id": "86206a1e"
      },
      "outputs": [],
      "source": [
        "# a method for loading weights into a parameter (torch layer)\n",
        "def assign(left,right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left : {left.shape} Right:{right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "0359b45c",
      "metadata": {
        "id": "0359b45c"
      },
      "outputs": [],
      "source": [
        "#assigning all the pretrained weights into their specific layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt,params):\n",
        "\n",
        "    gpt.pos_emb.weight=assign(gpt.pos_emb.weight,params['wpe'])\n",
        "    gpt.tok_emb.weight=assign(gpt.tok_emb.weight,params['wte'])\n",
        "    #weights for blocks inside transformer is stored in transpose\n",
        "    #blocks contains weight,bias values for all parameters in all heads for a single transformer\n",
        "    for b in range(len(params[\"blocks\"])):#blocks key stores all the weights required for all the 12 heads in the transformer block\n",
        "        #b- represents the head no\n",
        "        q_w,k_w,v_w=np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"],3,axis=-1)\n",
        "        #splitting the weight matrix into query,key,values. openai concatenated these weights  after transposing it. that's why it is splitted along column into 3 parts\n",
        "        gpt.trf_blocks[b].att.W_query.weight=assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight,q_w.T\n",
        "        )\n",
        "        gpt.trf_blocks[b].att.W_key.weight=assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight,k_w.T\n",
        "        )\n",
        "        gpt.trf_blocks[b].att.W_value.weight=assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight,v_w.T\n",
        "        )\n",
        "\n",
        "        q_b,k_b,v_b=np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"],3,axis=-1)\n",
        "        #splitting the bias matrix into query,key,values. openai concatenated these biases. that's why it is splitted along column into 3 parts\n",
        "        gpt.trf_blocks[b].att.W_query.bias=assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias,q_b\n",
        "        )\n",
        "        gpt.trf_blocks[b].att.W_key.bias=assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias,k_b\n",
        "        )\n",
        "        gpt.trf_blocks[b].att.W_value.bias=assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias,v_b\n",
        "        )\n",
        "\n",
        "        #loading the weights and biases for the output projection layer in the transformer block(last block)\n",
        "        gpt.trf_blocks[b].att.out_proj.weight=assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
        "        )\n",
        "        gpt.trf_blocks[b].att.out_proj.bias=assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
        "        )\n",
        "\n",
        "\n",
        "        #loading the weights and biases for feedforward NN layers(fully-connected layer:768 x 4*768 ,projection layer: 4*768 x 768)\n",
        "        #Fully-Connected layer\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight=assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
        "        )\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias=assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
        "        )\n",
        "\n",
        "        #projection layer\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight=assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
        "        )\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias=assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
        "        )\n",
        "\n",
        "\n",
        "        #loading weights for scale and shift parameters in normalization layers\n",
        "        #Layer Normalization 1\n",
        "        gpt.trf_blocks[b].norm1.scale=assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
        "        )\n",
        "        gpt.trf_blocks[b].norm1.shift=assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
        "        )\n",
        "        #Layer Normalization 2\n",
        "        gpt.trf_blocks[b].norm2.scale=assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
        "        )\n",
        "        gpt.trf_blocks[b].norm2.shift=assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
        "        )\n",
        "\n",
        "    #Final Normalization Layer in GPT\n",
        "    gpt.final_norm.scale=assign(gpt.final_norm.scale,params[\"g\"])\n",
        "    gpt.final_norm.shift=assign(gpt.final_norm.shift,params[\"b\"])\n",
        "\n",
        "    #Linear output layer in GPT (use the token embeddings weight for this layer-weight tying)\n",
        "    gpt.out_head.weight=assign(gpt.out_head.weight,params[\"wte\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "ff7ce49d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff7ce49d",
        "outputId": "24c415c7-10d8-41ae-99dc-67aa02aeaafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.20.0\n",
            "tqdm version:  4.67.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"Tensorflow version: \",tf.__version__)\n",
        "print(\"tqdm version: \",tqdm.__version__)\n",
        "\n",
        "\n",
        "#gpt_download3 is a file with functions for downloading and saving and loading gpt2 weights released by OpenAI\n",
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "settings,param=download_and_load_gpt2(model_size=\"124M\",models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "25a4473f",
      "metadata": {
        "id": "25a4473f"
      },
      "outputs": [],
      "source": [
        "#loading pretrained weights into my gpt2 model\n",
        "load_weights_into_gpt(gpt,param)\n",
        "# gpt.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "5c62f881",
      "metadata": {
        "id": "5c62f881"
      },
      "outputs": [],
      "source": [
        "#merge top-k sampling and temperature scaling\n",
        "\n",
        "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond=idx[:,-context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits=model(idx_cond)\n",
        "        logits=logits[:,-1,:]\n",
        "        #getting the last vector of output\n",
        "\n",
        "        if top_k is not None:\n",
        "\n",
        "            top_logits,top_pos=torch.topk(logits,top_k)\n",
        "            min_val=top_logits[:,-1]\n",
        "            logits=torch.where(logits<min_val,torch.tensor(float(\"-inf\")).to(logits.device),logits)\n",
        "\n",
        "        if temperature>0.0:\n",
        "            logits=logits/temperature\n",
        "\n",
        "            probs=torch.softmax(logits,dim=-1)#(batch_size,context_length)\n",
        "\n",
        "            idx_next=torch.multinomial(probs,num_samples=1)#(batch_size,1)\n",
        "\n",
        "        else:\n",
        "              idx_next=torch.argmax(logits,dim=-1,keepdim=True)\n",
        "\n",
        "        if idx_next==eos_id:#stop generating if end of sequence token is encountered\n",
        "            break\n",
        "\n",
        "        idx=torch.cat((idx,idx_next),dim=1) #(batch_size,num_tokens+1)\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "3e2f232c",
      "metadata": {
        "id": "3e2f232c"
      },
      "outputs": [],
      "source": [
        "#predefining methods to encoe and decode\n",
        "import tiktoken\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor=torch.tensor(encoded).unsqueeze(0) # adding batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "    flat=token_ids.squeeze(0) #remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "#example\n",
        "start_context=\"Every Effort moves you\"\n",
        "\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "18aada5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18aada5b",
        "outputId": "ed796cdb-4428-4e8e-b1d3-ea5bc5979177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:  How are you?? Why did you get it then, but only after watching my wife cry? If he's on TV then that would be one\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids=generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"How are you??\",tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text: \",token_ids_to_text(token_ids,tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "0ce8851a",
      "metadata": {
        "id": "0ce8851a"
      },
      "outputs": [],
      "source": [
        "#creating dataloaders for spam data\n",
        "\n",
        "#first, pad all messages to length of longest message(add endoftext tokens to smaller length message s until its length reachs to the longest message length)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data  import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    #max-length: length of the longest message\n",
        "    def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id=50256):\n",
        "        self.data=pd.read_csv(csv_file)\n",
        "\n",
        "        #pre-tokenize the texts\n",
        "        self.encoded_texts=[tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length=self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length=max_length\n",
        "\n",
        "            #Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts=[encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "\n",
        "        #Pad sequences to the longest sequences\n",
        "        self.encoded_texts=[encoded_text +[pad_token_id]*(self.max_length-len(encoded_text))\n",
        "                            for encoded_text in self.encoded_texts]\n",
        "\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #encoded: gets the each full message's token ids\n",
        "        encoded=self.encoded_texts[index]\n",
        "        #label: the value that tells whether the email is spam or not\n",
        "        label=self.data.iloc[index][\"Label\"]\n",
        "        if isinstance(label, str):\n",
        "          label = 1 if label.lower() == \"spam\" else 0\n",
        "        return (\n",
        "            torch.tensor(encoded,dtype=torch.long),\n",
        "            torch.tensor(label,dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length=0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length=len(encoded_text)\n",
        "            if encoded_length> max_length:\n",
        "                max_length=encoded_length\n",
        "        return max_length\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "c3b77d73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3b77d73",
        "outputId": "5dba0707-f6c6-430f-e155-9cde539a7b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset=SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)\n",
        "#the longest message length in  training data is 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "a874339a",
      "metadata": {
        "id": "a874339a"
      },
      "outputs": [],
      "source": [
        "val_dataset=SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "test_dataset=SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "6032398e",
      "metadata": {
        "id": "6032398e"
      },
      "outputs": [],
      "source": [
        "#creating dataloaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers=0\n",
        "batch_size=8 #each input batch will have 8 different input message's token ids\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader=DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "test_loader=DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "fc46914f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc46914f",
        "outputId": "f4bb67bf-119e-4cce-dac7-e5c519be3c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader: \n",
            "Input batch dimensions:  torch.Size([8, 120])\n",
            "Label batch dimensions:  torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader: \")\n",
        "for input_batch,target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions: \",input_batch.shape)\n",
        "#8 input messages(in token ids) with each message having 120 tokens(120:length of the longest message in whole dataset)\n",
        "print(\"Label batch dimensions: \",target_batch.shape)\n",
        "#8 inputs actual output classification value(spam or not spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "72ecf3ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ecf3ff",
        "outputId": "b2ceba82-5262-43c1-88bb-ec01d0289a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130 training batches\n",
            "18 validation batches\n",
            "37 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")\n",
        "#each batch contains 8 inputs with their target values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "58608129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58608129",
        "outputId": "248ad526-168d-47b8-e901-16e6630d8ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'gpt2-small (124M)': {'emb_dim': 768, 'n_layers': 12, 'n_heads': 12}, 'gpt2-medium (355M)': {'emb_dim': 1024, 'n_layers': 24, 'n_heads': 16}, 'gpt2-large (774M)': {'emb_dim': 1280, 'n_layers': 36, 'n_heads': 20}, 'gpt2-xl (1558M)': {'emb_dim': 1600, 'n_layers': 48, 'n_heads': 25}}\n"
          ]
        }
      ],
      "source": [
        "#initialing model with pretrained weights\n",
        "\n",
        "CHOOSE_MODEL=\"gpt2-small (124M)\"\n",
        "INPUT_PROMPT=\"Every effor moves\"\n",
        "\n",
        "BASE_CONFIG={\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_length\":1024,\n",
        "    \"drop_rate\":0.0,\n",
        "    \"qkv_bias\":True\n",
        "}\n",
        "\n",
        "print(model_configs)\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length<=BASE_CONFIG[\"context_length\"],(\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context\"\n",
        "    f\"length {BASE_CONFIG[\"context_length\"]}. Reinitialize data sets with max_length={BASE_CONFIG['context_length']}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "d108e3cd",
      "metadata": {
        "id": "d108e3cd"
      },
      "outputs": [],
      "source": [
        "model_size=CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")#output=124M\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "036b3385",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036b3385",
        "outputId": "116baafd-98ad-4c45-ed48-682f24cf7e3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ffmou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "#built functions in a file to download gpt 2 pretrained  weights\n",
        "from gpt_download3 import download_and_load_gpt2\n",
        "settings,param=download_and_load_gpt2(model_size=model_size,models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "a3a3a963",
      "metadata": {
        "id": "a3a3a963"
      },
      "outputs": [],
      "source": [
        "model=GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model,param)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "e1171cf5",
      "metadata": {
        "id": "e1171cf5"
      },
      "outputs": [],
      "source": [
        "#generating text from output token\n",
        "\n",
        "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
        "    #idx is inputs(batch size,num_of tokens)\n",
        "    #model- GPT-2 Model\n",
        "    #max_new_tokens-no of tokens to be predicted\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        #eg: if llm supports only 5 tokens, and the given context_size is 10\n",
        "        #then only last 5 tokens are used as context\n",
        "        idx_cond=idx[:,-context_size:]\n",
        "        #getting token ids in an input sequence only until context size limit\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits=model(idx_cond)##shape-(no_of_batches,no_of_tokens_in_each_input,vocab_size)\n",
        "\n",
        "        logits=logits[:,-1,:]#getting last row from each inputs of a btach\n",
        "\n",
        "        #applying softmax for finding probabilties. dim=-1 because values are summed up along column for each row\n",
        "        probabs=torch.softmax(logits,dim=-1)\n",
        "\n",
        "        #finding highest probabilty value index for each row\n",
        "        idx_next=torch.argmax(probabs,dim=-1,keepdim=True)\n",
        "\n",
        "\n",
        "        idx = torch.cat((idx,idx_next),dim=1)#(batch,n_tokens+1)\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "b7c83ab4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7c83ab4",
        "outputId": "c0d20cf9-60be-4043-fc58-2793872f134a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every Effort moves you to the next level.\n",
            "\n",
            "The goal is to get to the next\n"
          ]
        }
      ],
      "source": [
        "text_1=\"Every Effort moves you\"\n",
        "\n",
        "token_ids=generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1,tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids,tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "c9488a04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9488a04",
        "outputId": "c9995ff9-2628-4799-9567-af1775f8dbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "#check if without finetuning model can predict spam or not spam for a message\n",
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "91a8b286",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91a8b286",
        "outputId": "56b44d3f-929e-4769-d7a0-742519a581b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#adding a classification head to the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "f450e03a",
      "metadata": {
        "id": "f450e03a"
      },
      "outputs": [],
      "source": [
        "#replace the output_head(linear output layer with new classification head)\n",
        "#to modify the model, freeze the model with its parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "333faef7",
      "metadata": {
        "id": "333faef7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes=2\n",
        "#changed the final  linear output layer with (768 x 2)\n",
        "model.out_head=torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"],out_features=num_classes)\n",
        "#while changing out_head, this layer will change its requires_grad automatically true so that while training it only tracks parameters of this layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "12d0966f",
      "metadata": {
        "id": "12d0966f"
      },
      "outputs": [],
      "source": [
        "#last transformer block and last layer norm block\n",
        "#tracking these layers paramaters\n",
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad=True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "5f035833",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f035833",
        "outputId": "4220e8ed-4e3d-47c3-c5eb-63db1806695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs=tokenizer.encode(\"Do you have time\")\n",
        "inputs=torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\",inputs)\n",
        "print(\"Inputs dimensions:\",inputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "1100aaa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1100aaa3",
        "outputId": "8e01c1b5-ed0d-4381-ae4b-51eeaf463e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:  tensor([[[-1.5883,  0.9920],\n",
            "         [-3.7208,  7.4510],\n",
            "         [-2.2642,  6.6005],\n",
            "         [-3.5965,  3.9889]]])\n",
            "Output shape:  torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    output=model(inputs)\n",
        "\n",
        "print(\"Output: \",output)\n",
        "print(\"Output shape: \",output.shape )#shape changed from (batch_size,num_of_tokens,num_embeddings) to (batch_size,num_of_tokens,2) for a classification(yes or no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "9919e3a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9919e3a8",
        "outputId": "6172058d-fcd8-4d9f-a08c-e4f4918c8aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last output token:  tensor([[-3.5965,  3.9889]])\n"
          ]
        }
      ],
      "source": [
        "#use last output token vector because it covers all tokens in the whole input\n",
        "print(\"Last output token: \",output[:,-1,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "3021a5a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3021a5a8",
        "outputId": "355fa04e-5635-423a-f6ae-31e7f2a03ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class label:  1\n"
          ]
        }
      ],
      "source": [
        "#applying softmax and finding the index with largest probability\n",
        "probas=torch.softmax(output[:,-1,:],dim=-1)\n",
        "label=torch.argmax(probas)\n",
        "print(\"Class label: \",label.item())\n",
        "#1-spam 0-not spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "0b733a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b733a1a",
        "outputId": "15216e3a-a383-40cf-d533-9c0e0b693faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class label:  1\n"
          ]
        }
      ],
      "source": [
        "#directly finding largest valuw without softmax\n",
        "logits=output[:,-1,:]\n",
        "label=torch.argmax(logits)\n",
        "print(\"Class label: \",label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "053c442b",
      "metadata": {
        "id": "053c442b"
      },
      "outputs": [],
      "source": [
        "#applying argmax-based predicion to all examples and calculate accuracy for each batch of input\n",
        "\n",
        "def calc_accuracy_loader(data_loader,model,device,num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions,num_examples=0,0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches=len(data_loader)\n",
        "    else:\n",
        "        num_batches=min(num_batches,len(data_loader))\n",
        "\n",
        "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "        if i<num_batches:\n",
        "            input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits=model(input_batch)[:,-1,:] #logits of last output token\n",
        "            predicted_labels=torch.argmax(logits,dim=-1)\n",
        "\n",
        "            num_examples+=predicted_labels.shape[0]\n",
        "            correct_predictions+=(predicted_labels==target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return correct_predictions/num_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "6e0ff7d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e0ff7d3",
        "outputId": "305f0365-d272-4446-c013-1f8ea85b6463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 53.75%\n",
            "Testing accuracy: 50.00%\n"
          ]
        }
      ],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_accuracy=calc_accuracy_loader(train_loader,model,device,num_batches=10)\n",
        "val_accuracy=calc_accuracy_loader(val_loader,model,device,num_batches=10)\n",
        "test_accuracy=calc_accuracy_loader(test_loader,model,device,num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Testing accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "df67ce11",
      "metadata": {
        "id": "df67ce11"
      },
      "outputs": [],
      "source": [
        "#calculating cross entropy loss for single batch of input\n",
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "    input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n",
        "    logits=model(input_batch)[:,-1,:]#taking last vector for all of the inputs in each batch as predicted vector\n",
        "    loss=torch.nn.functional.cross_entropy(logits,target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "88987081",
      "metadata": {
        "id": "88987081"
      },
      "outputs": [],
      "source": [
        "#calculating cross entropy loss for single data loader\n",
        "\n",
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "    total_loss=0\n",
        "    if len(data_loader)==0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches==0:\n",
        "        num_batches=len(data_loader)\n",
        "    else:\n",
        "        num_batches=min(num_batches,len(data_loader))\n",
        "\n",
        "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "        if i<num_batches:\n",
        "            loss=calc_loss_batch(input_batch,target_batch,model,device)\n",
        "            total_loss+=loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss/num_batches\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "b7d457d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7d457d3",
        "outputId": "4a424232-c25e-4c8c-ad7d-337ea1c383d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 3.200\n",
            "Validation Loss: 2.428\n",
            "Testing Loss: 2.543\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    train_loss=calc_loss_loader(train_loader,model,device,num_batches=5)\n",
        "    val_loss=calc_loss_loader(val_loader,model,device,num_batches=5)\n",
        "    test_loss=calc_loss_loader(test_loader,model,device,num_batches=5)\n",
        "\n",
        "print(f\"Training Loss: {train_loss:.3f}\")\n",
        "print(f\"Validation Loss: {val_loss:.3f}\")\n",
        "print(f\"Testing Loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "08147a0e",
      "metadata": {
        "id": "08147a0e"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "    model.eval()#disable dropout and gradient tracking\n",
        "    with torch.no_grad():\n",
        "        train_loss=calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "        val_loss=calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss,val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "25d6659e",
      "metadata": {
        "id": "25d6659e"
      },
      "outputs": [],
      "source": [
        "#finetuning model on supervised data\n",
        "#training process\n",
        "\n",
        "def train_classifier_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter):\n",
        "\n",
        "    train_losses,val_losses,train_accs,val_accs=[],[],[],[]\n",
        "    examples_seen,global_step=0,-1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()#set model to training model\n",
        "\n",
        "        for input_batch,target_batch in train_loader:\n",
        "            optimizer.zero_grad() #reset loss gradients from previous batch iteration\n",
        "            loss=calc_loss_batch(input_batch,target_batch,model,device)\n",
        "            loss.backward()#calculate loss gradients\n",
        "            optimizer.step()#update model weights using loss gradients\n",
        "            examples_seen+=input_batch.shape[0]\n",
        "            global_step+=1\n",
        "\n",
        "            #evaluation step\n",
        "            if global_step%eval_freq==0:\n",
        "                train_loss,val_loss=evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f} , Val loss {val_loss: .3f}\")\n",
        "\n",
        "            train_accuracy=calc_accuracy_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "            val_accuracy=calc_accuracy_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "            print(f\"Training accuracy: {train_accuracy*100:.2f}% | \",end=\"\")\n",
        "            print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "            train_accs.append(train_accuracy)\n",
        "            val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses,val_losses,train_accs,val_accs,examples_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "19ea3328",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ea3328",
        "outputId": "7b20d906-21d6-4bbf-ff05-481b540ade51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 (Step 000000): Train loss 0.688 , Val loss  0.493\n",
            "Training accuracy: 62.50% | Validation accuracy: 50.00%\n",
            "Training accuracy: 42.50% | Validation accuracy: 57.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 75.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 70.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 75.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 77.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 72.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 77.50%\n",
            "Training accuracy: 75.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Epoch 1 (Step 000050): Train loss 0.376 , Val loss  0.310\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 77.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 77.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Epoch 1 (Step 000100): Train loss 0.298 , Val loss  0.360\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 70.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 77.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 77.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 77.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 77.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 77.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 75.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 75.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 67.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 72.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Epoch 2 (Step 000150): Train loss 0.386 , Val loss  0.176\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 75.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 75.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 75.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 77.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Epoch 2 (Step 000200): Train loss 0.411 , Val loss  0.515\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 75.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 75.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 80.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 77.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 75.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 75.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 77.50% | Validation accuracy: 82.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 82.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Epoch 2 (Step 000250): Train loss 0.229 , Val loss  0.230\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 80.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 80.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Epoch 3 (Step 000300): Train loss 0.258 , Val loss  0.101\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 85.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Epoch 3 (Step 000350): Train loss 0.067 , Val loss  0.089\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Epoch 4 (Step 000400): Train loss 0.158 , Val loss  0.102\n",
            "Training accuracy: 87.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Epoch 4 (Step 000450): Train loss 0.127 , Val loss  0.082\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Epoch 4 (Step 000500): Train loss 0.222 , Val loss  0.083\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Epoch 5 (Step 000550): Train loss 0.104 , Val loss  0.011\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 87.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Epoch 5 (Step 000600): Train loss 0.113 , Val loss  0.173\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 92.50% | Validation accuracy: 100.00%\n",
            "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 7.37 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "e1bb674c",
      "metadata": {
        "id": "e1bb674c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "06a290a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "06a290a8",
        "outputId": "b0a2525d-8d69-439a-9305-68671c3c8bbb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "5ee4a93a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "5ee4a93a",
        "outputId": "694a860b-9b70-4119-ff29-76c4f0ec6056"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "d2620b15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2620b15",
        "outputId": "1256e898-be67-4e22-fb1e-5d00817b2df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 56.25%\n",
            "Validation accuracy: 55.00%\n",
            "Testing accuracy: 45.00%\n"
          ]
        }
      ],
      "source": [
        "#calculating accuracy for whole dataset\n",
        "train_accuracy=calc_accuracy_loader(train_loader,model,device,num_batches=10)\n",
        "val_accuracy=calc_accuracy_loader(val_loader,model,device,num_batches=10)\n",
        "test_accuracy=calc_accuracy_loader(test_loader,model,device,num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Testing accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "ebeaea92",
      "metadata": {
        "id": "ebeaea92"
      },
      "outputs": [],
      "source": [
        "#using the llm as a classifier for spam classification\n",
        "#method is for single input message\n",
        "def classify_review(text,model,tokenizer,device,max_length=None,pad_token_id=50256):\n",
        "    #max-length: longest message length in the dataset\n",
        "\n",
        "    input_ids=tokenizer.encode(text)\n",
        "    supported_context_length=model.pos_emb.weight.shape[0] #shape of positional embedding=(1024 x 768)\n",
        "\n",
        "    #truncate sequnes if they are too long\n",
        "    input_ids=input_ids[:min(max_length,supported_context_length)]\n",
        "\n",
        "    #adding end of token id to pad sequences if they are shorter than the max_length\n",
        "    input_ids+=[pad_token_id]*(max_length-len(input_ids))\n",
        "    input_tensor=torch.tensor(input_ids,device=device).unsqueeze(0) #add batch dimension\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits=model(input_tensor)[:,-1,:] #logits of the last output token\n",
        "    predicted_label=torch.argmax(logits,dim=-1).item()\n",
        "\n",
        "    return \"spam\" if predicted_label==1 else \"not spam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "e7b1b473",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b1b473",
        "outputId": "d08bad0c-f4a2-4d0b-da1d-26da189306b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam\n"
          ]
        }
      ],
      "source": [
        "#example of a spam message\n",
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "6f17cf65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f17cf65",
        "outputId": "e0ae718e-a5a0-41e6-9f2d-b02f4034f434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "#example of a non spam message\n",
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74270ea6",
      "metadata": {
        "id": "74270ea6"
      },
      "outputs": [],
      "source": [
        "# #storing weights\n",
        "# torch.save(model.state_dict(),\"review_classifier.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "cb4241d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb4241d7",
        "outputId": "b110f6bb-037a-4c02-f9dc-a9847da545dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading weights into model\n",
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=torch.device(\"cpu\"))\n",
        "model.load_state_dict(model_state_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V6DD7Hj7IaM5",
      "metadata": {
        "id": "V6DD7Hj7IaM5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
